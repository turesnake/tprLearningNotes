# ================================================================ #
#                  unity3d  待做清单
# ================================================================ #



# --- 008 --- #
部分 shader 在 imac 中无法正常允许，需要到 pc 中调试
比如 geometric shader


# --- 009 --- #
光照衰减 纹理查找表： Lookup Table LUT 
去 manual 中学习这方面的知识


# --- 010 --- #
学习 ScriptableWizard 的使用


# --- 012 --- #
在 win 平台 安装 RenderDoc


# --- 013 --- #
brdf 学习：
Cook-Torrance 库克-托伦斯
    貌似是表现最好的

Torrance-Sparrow 微面元模型

Ward Isotropic 
    据说 Ward 在表现 各向异性 材质时最好

microfacet distribution fit
    比 ward 更好的，表现 各向异性 的材质

Lafortune Lobe

GGX -- 法线分布函数 （Trowbridge-Reitz 法线分布函数）

Beckmann -- 法线分布函数



# --- 016 --- #
为什么 菲涅尔 公式中，要使用 sin值 
为什么是 sin ？？？
《Real-Time Rendering》p-319



# --- 018 --- #
学习 ScriptableObject


# --- 019 --- #
阅读 manual: Occlusion culling

阅读 manual: Shadow
    RTR chapter 7: shadows


# --- 019 --- #
各种实际应用中的矩阵，是怎么推导出来的


# --- 020 --- #
《RTR》p-226:
    平面表达式：π:n·x+d=0
    这是啥意思
# :
根据后续文字，π 是这个平面的变量名，冒号后的 表达式 暂时未知



# --- 028 --- #
catlike 
尝试搞懂 ConvertToAtlasMatrix 到底对矩阵做了啥



# --- 030 --- #
urp 中的函数 GetShadowTransform()
是和 catlike 中的 ConvertToAtlasMatrix() 相似功能的
需要查看



# --- 031 --- #
为什么函数 ComputeDirectionalShadowMatricesAndCullingPrimitives
要返回 两个矩阵？pjt 和 view
为什么两个矩阵叫这么名字

原本，我们需要获得一个矩阵，可以将 pos 从 ws，转换到 STS 空间




# --- 032 --- #

o.depth = -mul(UNITY_MATRIX_MV, v.vertex).z * _ProjectionParams.w;
乘法的前者，获得顶点在 view-space 中的 pos（且 z轴翻转了，是正的）
然后取 posVS.z, 乘以 _ProjectionParams.w
也就是 1/far

获得一个区间值 [0,1] 其中 
0: camera pos
1: far

这恰恰是 Linear01Depth() 实现的

然后我们可以到 frag 中，获得每个像素的 映射值



# --- 033 --- #
查看：
OnRenderImage
OnPostRender

OnWillRenderObject
    to find out if an object is seen by a camera or not

camera.depthTextureMode = DepthTextureMode.Depth
    it's just there when running deferred
    Then the depth buffer will be available as _CameraDepthTexture
    

    glancing(dot(view, normal))


# --- 034 --- #
在 urp manual: Feature comparison table 中：
    builtin shading - Multiple Passes
    urp shading - Single Pass


# --- 036 --- #
为什么 camera depth buffer 的写入工作
    urp 依赖 depthOnly pass
    builtin 依赖 shadow caster pass ？？？



# --- 038 --- #
camera 相关的数据：
    _CameraColorTexture
    _CameraDepthTexture
    _CameraDepthNormalsTexture -- not support in urp



# --- 044 --- #
有空阅读 hdrp 的基础知识


# --- 050 --- #
实现一份 urp 版的 outline 效果：
进展：
    成功将代码移植到 urp 普通 shader 中
    但是似乎存在问题：
    outline 看起来更适合成为 后期特效，比如 feature，
    而不是 普通特效
    因为 边界线理论上是会溢出模型的，但是一旦受限于 普通特效，这一点就实现不了了 



# --- 051 --- #
实现一个简单的，动态 perlin noise texture
笼在一个球上

Mathf.PerlinNoise()

出于性能考虑，shader 也许并不真的 “每帧都去计算 perlin noise”
而是 预先制作好一张 noise texture，然后变得法子使用它。



# --- 052 --- #
-1-
如何渲染一个 缩小的球 ？？？
    准备一个 sphere，实际渲染时，渲染一个 缩小了半径的球
    外部部分 变成透明的

    这个思路可以搞定各种 半透明边界 的视觉效果 

-2-
如何实现：
我们渲染一个 球，但是我们只是利用它的 剪影区间，
实际显示出来的是一张永远面向视线的，扁平的材质 ？？？ 
    这也许比 渲染 缩小的球 要简单

-3-
简化上述方案：
    用一张始终面向 camera 的 方型片元 quad 来承载 火球：
    ---
    从 cs 将核心数据传递给 gpu，用来描述那个不存在的 数字空间
    ---
    火球自己具备一个 三位坐标，通过三个轴的 单位向量来表达，记录它们的 dirWS
    就能在 shader 中重组出 矩阵，从而能将一个 火球面上的 碰撞点，变换为一个 
    基于 火球坐标系的 dir 向量
    ---
    根据这个 dir 向量，就能计算出 texcoord， 即 uv坐标
    这是第一步目标
    为了验证这个 uv 坐标的正确性，可以尝试用它来 蒙一张 texture，查看效果 
    ---






# --- 053 --- #
学习如何用 unity 生成一张 texture png 文件
# --- 054 --- #
当我们生成一张 heightmap 时（grayscale-map）
如何在 runtime 将其计算为一张 normalmap ???
# --- 055 --- #
改进 TprInput：
    在程序启动时，让 camera 停留在原地，并自动修改 emptyHero 的位置
# --- 056 --- #
当使用 clip(), 人为将 一个 opaque mesh 处理成镂空时
此帧的 depth-buffer 长啥样 ？？？
# --- 057 --- #






# --- 058 --- #

# --- 059 --- #

# --- 060 --- #

# --- 061 --- #

# --- 062 --- #

# --- 063 --- #

# --- 064 --- #

# --- 065 --- #

# --- 066 --- #


