# ================================================================ #
#                  unity3d  已答问题
#                 （待做清单 的完成部分）
# ================================================================ #
相当一部分问题片段 已经丢失...

  


# ====================== 029 ============================ #
# unity 中， z-buffer 取值范围到底是多少
# 它和 depth buffer 之间的转化是怎么样的 
# ------------------------------------------------------- #
    z-buffer 就是 depth buffer
    是一个非线性的 [0,1] 区间，
    除 opengl 以外的 大部分平台，都已经支持 reverseZBuffer
    即：
        0: far
        1: near

    至于为什么要将 z值 0-1 反转，推荐看 《RTR》 p-100 页
        简单说就是：浮点数的精度分布不是均匀的：越接近0，精度分布越密集。
        这与 原始 z值 分布正好相反，在齐次除法后(除w),
        z值才 0-1 区间呈 不均匀分布，越接近1，分布密度越高。
        即，画面远处的物体，z值 误差越大。
        通过 reverseZBuffer （0-1 反转）两个不均匀分布被中和了。
    

# ====================== 032 ============================ #
# 
# ------------------------------------------------------- #
    
o.depth = -mul(UNITY_MATRIX_MV, v.vertex).z * _ProjectionParams.w;
乘法的前者，获得顶点在 view-space 中的 pos（且 z轴翻转了，是正的）
然后取 posVS.z, 乘以 _ProjectionParams.w (也就是 1/far)

获得一个区间值 [0,1] 其中 
0: camera pos
1: far

这恰恰是 Linear01Depth() 实现的

然后我们可以到 frag 中，获得每个像素的 映射值



# ====================== 035 ============================ #
#     如何在 urp 中实现 z-buffer show ?
# ------------------------------------------------------- #

    需要事先准备好 depthOnly pass,
    以便把数据，填入 _CameraColorTexture


# ====================== 040 ============================ #
# 什么是 G-Buffer (geometry buffer)
# ------------------------------------------------------- #

    builtin manual 将 camera depth, depth+normals, or motion vector Texture
    看作是 最简单的 G-Buffer texture
#
    GBuffer 被认为 和 Deferred shading 有关
#
    The G-buffer is the collective term of all textures used to store lighting-relevant data 
    for the final lighting pass.


# ====================== 041 ============================ #
# unity 支持 MRT (multiple render targets) 吗 ？
# ------------------------------------------------------- #

    builtin,urp 可以手动支持
    hdrp 因为是 deferred shading，所以天生支持 mrt



# ====================== 043 ============================ #
# Deferred shading 的缺点 ?
# ------------------------------------------------------- #
- 因为依赖 z-buffer, 所以不擅长表现 半透明物体
    现代硬件似乎有对策
- 不适合 multiple materials
    这会增加显存开销
- 因为将 geometric 和 lighting 分离了，基于硬件的 anti-aliasing 不再表现良好
    但是似乎存在新技术


# ====================== 045 ============================ #
# urp  是否支持 forward / deferred rendering
# hdrp 是否支持 forward / deferred rendering
# ------------------------------------------------------- #

    urp 支持 forward rendering
    urp 的 deferred rendering 还在开发中

    hdrp 同时支持 forward / deferred rendering
    hdrp 不光都支持，还支持运行时 在两种 模式之间切换



# ====================== 047 ============================ #
# 什么是 _MainTex_TexelSize ?
# ------------------------------------------------------- #

# float4 _MainTex_TexelSize;
    假设 texture 的长宽为 (w,h) [pix]
    此值为 ( 1/w, 1/h, w, h )
---
[此段存疑]
    y is negative when it belongs to a RenderTexture that has 
    been flipped vertically by D3D anti-aliasing.
    ---
    在官方 munaul 中，也没提到这段



# ====================== 048 ============================ #
# shader_feature 与 multi_compile 的区别 
# ------------------------------------------------------- #
# :
    manual: Shader variants and keywords
#
    两种格式的最终目的 都是为了生成 关键词 / keywords
        以此来达成 宏分支，最终生成不同的 shader variant
        毕竟在 shader 中，分支语句是十分昂贵的
        --
    进一步的，也可以在运行时 修改 keyword 的状态：enable/disable
        以此来在不同的 shader variants 之间切换

# #pragma multi_compile Sml Mid Big 
    unity 查找 这三个 keywords 是否在 cs文件中被 enable
    如果一个都没被 enable，就启用第一个
    （所以它们不能被分开写成数行）

# multi_compile 中 "_" 的意义
    在原始实现中，如果我们想要实现一个 开关 功能，我们需要这样做
        #pragma multi_compile AOn AOff
    要么 enable AOn keyword，要么 enable AOff keyword
    这会造成 keywords 数量的膨胀，
    而 unity shader 中，keywords 数量是有上限的
    ---
    一种对策就是：
        #pragma multi_compile _ AOn
    在这种实现中，只存在一个 keyword，如果 AOn 未被 enable
    则 unity 自动 enable "_", 而这个 keyword 是 “功能上无意义的”
    也就是说， "_" 虽然是一个正确的 keyword，但我们不会在 代码中用到它
    从而实现 节省 keyword 的目的

# shader_feature 与 multi_compile 的区别 
    The only difference is that Unity does not include 
    unused variants of shader_feature shaders in the final build. 
---
    For this reason, you should use shader_feature for keywords that are set from the Materials, 
    while multi_compile is better for keywords that are set from code globally.
---
    shader_feature 可以认为是 multi_complie 的子集，其与 multi_complie 最大的不同就是
    此关键字的声明变体是材质球层级的（multi_complie是全局），只能通过美术在制作时调整相应材质，
    未被选择的变体会在打包的时候被舍弃（multi_complie不会），所以其声明的变体是不能通过代码控制的（打包后会出问题）

# 
        #pragma shader_feature A
    等于 #pragma shader_feature _ A
    这只是一种简写
        ---
        但是，这个简写，只在 本行只有一个 keyword 时才有效
        当有数个 keywords 时，就会自动默认 第一个 keyword 是 enable 的

# local keyword 可以由谁来改 ？
    mat.EnableKeyword();
    使用其它方式 只能修改 global keywords, 不会起作用 




# ====================== 061 ============================ #
# 通过 mod(pos)， 可以在空间中渲染无数个整齐排列的 mesh
# 问题来了：
# 在这个场景中，对于单个 frag 的检测，它需要针对多少个 mesh 进行 检测？
# ------------------------------------------------------- #

    代码：
    float repeatedCubes(vec3 p) {
        p.x = mod(p.x, 1) - 0.5;
        p.z = mod(p.z, 1) - 0.5;
        return cube(p);
    }
    每一次检测，它只需要检测一个 mesh ！！！
    由带么可知：晶格的长度是 1，任何一个检测点 p，一定只会和自己晶格的 cube 最接近
    所以，只要计算一次，获得 t，然后步进即可。
#
    但是，这个算法的渲染速度仍然是缓慢的：
        每一个像素点在命中最终 cube 之前，走得都不会很快，
        这意味着，步进速度会退化为 constant speed
        进而导致渲染变慢


# ====================== 064 ============================ #
#    什么是 Directional derivative
# ------------------------------------------------------- #

    函数 f(x,y) 在 x 轴上的 偏导数，其实就是 函数在方向 (1,0) 上的 方向导数
    计算公式:
        Df(x,y) = dot( 梯度向量, 方向V );
        Df(x,y,z) = dot( 梯度向量, 方向V );
        ---
        由 dot 运算可知，任何维度函数的 方向导数，一定是个一维值。
#
    对于 f(x,y) 而言，最终生成的结果，是一个 一维值（在方向V 上的导数）
    对于 f(x,y,z) 而言，最终生成的结果，也应该是一个 一维值 
# 快速计算法
    按照公式，最正式的计算当然是先算出 梯度，然后做 dot 运算。
    但是如果 梯度 计算本身就能麻烦，比如使用 central diffence method
    (意味着要做 4～6 次 采样)
    那么还存在一种更快速的，计算 方向导数 的方法：
    只采样 2 次：
    原始位置 采样一次，再沿着 方向V 前进一个微小距离 eps,然后再采样一次
    就能立刻求出 方向导数
# 方向导数 == 光照强度
    两者的公式是完全一样的: dot( normal, lightDir );
    所以，如果我们只是想 简单地计算 光照强度，
    那么完全没必要 计算 梯度（法线），然后再dot
    而是直接用上文的 快速计算法，计算最终值
    ---
    参考 iq 文:
    https://iquilezles.org/www/articles/derivative/derivative.htm




# ====================== 066 ============================ #
# 如何设置 垂直同步 VSync
# ------------------------------------------------------- #

    Edit - Project Setting - Quality - VSync Count: Don't sync


# ====================== 068 ============================ #
# unity urp 中，最终显示颜色 与 目标色 不同，
# ------------------------------------------------------- #
    问题处在 Gamma / Linnear 上
    原始素材中的颜色，默认是 Gamma 空间的
    但 urp 默认显示为 Linear
    此时整个画面会变得更亮更淡
    ----
    记得用 Gamma20ToLinear() 来转化


# ====================== 080 ============================ #
#     "pragma" 是什么意思 ?
# ------------------------------------------------------- #

    源自希腊语, 意味着行动, 或者需要做的事.
    它被很多编程语言所使用, 用来指示一个 特殊的 编译指令



# ====================== 081 ============================ #
#    SV_POSITION SV_TARGET 中的 "SV" 前缀是啥意思 ?
# ------------------------------------------------------- #
在 微软文档中有解释,为:
    system-value


# ====================== 082 ============================ #
#                啥是  Culling Mask ?
# ------------------------------------------------------- #

# --- Camera
仅是 Camera Inspector 中的一个列表选项, 列表成列了所有的 layers,
你可以勾选若干个. 勾选的 layer 将被这个 camera 渲染.

    未勾选的 layers 中的 物体, 则会被 culling ??? 存疑


# --- Light
未被选中的 layer, 所属的物体 将无法接收到 本光源的 光照. 

但是如果 rp 启用了 per-object light indices 功能, 它的 Culling Mask 将出现一点问题.




# ====================== 083 ============================ #
#      TransformWorldToObjectDir()
#      TransformWorldToObjectNormal()  两函数中的 mul 操作是什么原理 ?
#
#   方向向量/法线 在使用 矩阵乘法实现 空间变换 时, 如何计算 ?
#
# ------------------------------------------------------- #
观察:
    TransformObjectToWorldDir
    TransformObjectToWorldNormal

两个函数的实现 而 发现的问题.

具体回答请本 学习笔记 中搜索: Math / 线性代数 / 方向向量_法线_空间变换.jpg
它是对 冯乐乐 4.7章节, P-86 的整理

# 
其核心技术为:
    使用:
        mul( V, M的逆矩阵 ) 
    来代替:
        mul( M的逆转置矩阵, V )

    因为前者更简单, 只需准备好 原变换矩阵的 逆矩阵即可, 不需要再准备 逆转置矩阵.



# ====================== 084 ============================ #
#   为何 光源的 VisibleLight.localToWorldMatrix 矩阵 的第三列 能代表 光源的照射方向.
#   (OS->WS)
# ------------------------------------------------------- #

visibleLight.localToWorldMatrix.GetColumn(2)
(对此向量取负, 则能获得 光源入射方向: 受光点->光源 )

# 在 OS 中, 光源的 Z轴代表 照射方向.
    平行光, spot 光, 面光源, 都符合此条件.
    即: directionOS = float4( 0, 0, 1, 0 );

# 当执行 OS->WS矩阵 和 directionOS 的乘法后, 最终会直接得到 矩阵的 第三列. 
    这个向量表达的, 恰恰就是: 光源在 WS 中的 Z轴方向.

    同理可推导出:
    矩阵的第一列: 光源在 WS 中的 X轴方向.(right)
    矩阵的第二列: 光源在 WS 中的 Y轴方向.(up)

更具体地描述, 可在笔记中查找: 光源矩阵的含义.jpg



# ====================== 087 ============================ #
#       什么是: 上采样 / 下采样
# ------------------------------------------------------- #
上采样 (upsampling)
    ---
    放大 texture, 显示在更高分辨率屏幕上, 会出现颗粒化.

下采样 (subsampling)
    ---
    缩小 texture, 将一个区域的 texels, 放入一个像素中.




# ====================== 095 ============================ #
#       render texture / texture
#       render target,
#       camera
#       viewport
#   这些尺寸之间的关系 ?
# ------------------------------------------------------- #
以下内容一部分是我猜测的...

# camera 的渲染尺寸 是怎么来的 ?
    camera 可以直接渲染进 backbuffer, 也可渲染进一个 render target (其实就是个 texture)
    当 camera 的渲染目标被设置为 backbuffer (默认) 或某个 render target 时, 
    camera 都默认: 这个 backbuffer/render target 有多大, 自己就渲染多大的尺寸;

    以下简称 backbuffer / render target 为 "target";

    之后, 可以设置 "Camera.pixelRect", 写入的参数是一个 用户希望的区域(像素为单位),
    这个区域会被 "target" 的区域 clamp, 得到一个位于 "target" 区域之内的区域;
    (如果参数设置的区域 完全和 "target" 不相交, 那么这个camera 最终啥也不会被渲染)

    如果我们为 camera 绑定了 render target, 那么可直接调用 "CommandBuffer.SetViewport()",
    它能完成一样的功能;

# 当把一个 render texture 绑定为 render target 时, 这个 texture 的尺寸是不会发生改变的 !!!!!!


# 如果我们的 backbuffer 只有 100x100, 但是 render target 有 500x500, 该怎么办 ?
    -1- render target 依然是 500x500;
    -2- camera 默认写入整个 render target, 即, camera 写入的区域也是 500x500;
    -3- 调用 "CommandBuffer.SetViewport()", 传入参数 (0, 0, 100, 100),
        可以让 camera 只在 render target 左下角的 (100,100) 区域渲染内容
    -4- 调用 Blit(), 把这个 小区域的内容, 复制到 backbuffer 中

# "current resolution", "current reference size",  是啥意思 ?
    就是 当前帧的 虚拟的 backbuffer 的分辨率;
    简单点就可理解为 "游戏窗口" 的分辨率;
    (当然, 考虑到 动态分辨率的存在, 可能存在缩放, 但大致是这个意思)
    反正不是 texture / render texture / RTHandle texture 的尺寸;














    

